{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unauthorized-architect",
   "metadata": {},
   "source": [
    "# Using Python to examine HH-suite results - example making multi-fasta sequence format from query and hit sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-investment",
   "metadata": {},
   "source": [
    "Run this in sessions launched from [my HH-suite3-binder repo](https://github.com/fomightez/hhsuite3-binder) because the software is already installed.   \n",
    "This follows from the notebook in this series entitled [Using Python to examine HH-suite3 results](Using%20Python%20to%20examine%20HH-suite3%20results.ipynb).\n",
    "\n",
    "Here, will demonstrate using the basics from that previous notebook a specific example of going from the text based HH-suite3 results output files, which end in `.hhr`, to convert the sequence alignment in the query and hit match of be aligned multi-FASTA. This is similar to the format that I-TASSER needs to submit an alignment, and so can be a useful step if you now want to model the structure of homolog using HH-suite3 sequence alignment when the macromolecular structure for the query is already known.\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!.</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them. When you hover over them an <i class=\"fa-step-forward fa\"></i> icon appears.</li>\n",
    "        <li>To run a code cell either click the <i class=\"fa-step-forward fa\"></i> icon, or click on the cell and then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterix will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-conditioning",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "This preparation is based on what is already covered in entitled [Using Python to examine HH-suite3 results](Using%20Python%20to%20examine%20HH-suite3%20results.ipynb); however, does not require you to have run that recently. Just run everything under this 'Preparation' section to continue on with the rest of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-motivation",
   "metadata": {},
   "source": [
    "Get the `hhsuite3_results_to_df.py` script that will be used to mine the results files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_needed = \"hhsuite3_results_to_df.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -OL https://raw.githubusercontent.com/fomightez/sequencework/master/hhsuite3-utilities/hhsuite3_results_to_df.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-spirituality",
   "metadata": {},
   "source": [
    "Get some example files with  HH-suite3 query results.  \n",
    "For ease, I'll just some of the results files that the biopython package uses to test the parsing code is working well. They are publically available [here](https://github.com/biopython/biopython/tree/master/Tests/HHsuite); the `README` file [there](https://github.com/biopython/biopython/tree/master/Tests/HHsuite) summarizes the content of those files.\n",
    "\n",
    "If you prefer to use your own result files, upload your file to this session and change the appropriate file names in later steps.  \n",
    "(Note for a couple of the `.hhr` files, I noticed they had `Done!` close to the last line of the file; however, I hadn't seen that in the `.hhr` files from HH-suite3 that I developed with and it caused errors for my `hhsuite3_results_to_df.py`. To make them more consistent, I'm removing that, assuming it is from format version of HH-suite since biopython which is a source of these test files mentions that version in the current documentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "handmade-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 17947  100 17947    0     0  41834      0 --:--:-- --:--:-- --:--:-- 41834\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 38142  100 38142    0     0   164k      0 --:--:-- --:--:-- --:--:--  164k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 39235  100 39235    0     0  49980      0 --:--:-- --:--:-- --:--:-- 49917\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 40978  100 40978    0     0  98268      0 --:--:-- --:--:-- --:--:-- 98268\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files_needed = [\"hhsearch_q9bsu1_uniclust_w_ss_pfamA_30.hhr\",\n",
    "                \"2uvo_hhblits.hhr\",\n",
    "                \"2uvo_hhsearch.hhr\",\n",
    "                \"hhpred_9590198.hhr\"]\n",
    "url_prefix = \"https://raw.githubusercontent.com/biopython/biopython/master/Tests/HHsuite/\"\n",
    "for file_needed in files_needed:\n",
    "    if not os.path.isfile(file_needed):\n",
    "        !curl -OL {url_prefix+file_needed}\n",
    "!sed -i 's/Done!//g' 2uvo_hhblits.hhr\n",
    "!sed -i 's/Done!//g' 2uvo_hhsearch.hhr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-force",
   "metadata": {},
   "source": [
    "Define a function to deal with breaking up long sequence into chunks useful for lines of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "choice-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/fomightez/structurework/blob/0580b7470a866f5dc9f75aaf5200a5a5415b4f5d/pdbsum-utilities/similarities_in_proteinprotein_interactions.py#L161\n",
    "def generate_seq_chunks(seq_string, chunk_size = 60):\n",
    "    '''\n",
    "    This takes a sequence as a string and breaks it up into list of strings of\n",
    "    set length with graceful handling of the last line that will most likely\n",
    "    not be full length. \n",
    "    The list of sequence strings gets returned\n",
    "\n",
    "    `chunk_size = 60` sets residues per line to have in FASTA; note this \n",
    "    #chunking to multiple lines is the opposite of what PatMatch's \n",
    "    # `unjustify_fasta.pl` does. \n",
    "\n",
    "    Note `chunk_size` defaults to 60 here but optionally a different one\n",
    "    can be provided.\n",
    "\n",
    "    I believe my chunking code is based on \n",
    "    https://stackoverflow.com/a/13673133/8508004 or \n",
    "    https://stackoverflow.com/a/9475354/8508004 , see my gist \n",
    "    https://gist.github.com/fomightez/ef7583919dde51f3569731ca1c5247ba for some \n",
    "    notes on it and more related.\n",
    "    There's a related code in my script \n",
    "    `similarities_in_proteinprotein_interactions.py` inside my repo \n",
    "    structurework/pdbsum-utilities/  and in \n",
    "    `Searching for homologs among deduced proteins from a genome using BLAST and Python.ipynb`\n",
    "    & `Searching for coding sequences in genomes using BLAST and Python.ipynb`\n",
    "    & `notebooks/GSD/GSD Rpb1_orthologs_in_1011_genomes.ipynb` inside my repo \n",
    "    blast-binder.\n",
    "    '''\n",
    "    return [seq_string[i:i+chunk_size] for i in range(\n",
    "        0, len(seq_string),chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-object",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Using hhsuite parsing code from biopython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-trust",
   "metadata": {},
   "source": [
    "This section builds on the section 'Using hhsuite parsing code from biopython' from [Using Python to examine HH-suite3 results](Using%20Python%20to%20examine%20HH-suite3%20results.ipynb). You'll want to review that notebook first if you are having any issues following along some of the initial steps to access the `.hhr` file and parse it.\n",
    "\n",
    "This approach uses biopython to parse HH-suite3 results `.hhr` file to Python objects that play well with biopython / Python. Biopython has already been installed here. If you are trying to run this Jupyter notebook elsewhere, you'd need to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "active-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SearchIO import parse # import module of Biopython needed into active kernel namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-centre",
   "metadata": {},
   "source": [
    "The next command will parse an `.hhr` file. Note that `, \"hhsuite2-text\"` part specifies the format the biopython parser will use. If you've paid attention, you'll know HH-suite3 is the current release. It looks like Biopython hasn't caught up with that yet; however, fortunately, I've verified the `hhsuite2-text` option seems to work with current, HH-suite3-produced `.hhr` files to a great extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opposite-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_file_info = parse(\"hhsearch_q9bsu1_uniclust_w_ss_pfamA_30.hhr\", \"hhsuite2-text\") # based on test_SearchIO_hhsuite2_text.py and https://biopython.org/docs/1.75/api/Bio.SearchIO.html\n",
    "results = list(parsed_file_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-turkish",
   "metadata": {},
   "source": [
    "Here, I just want to deal with the best hit, so `results[:1]` and `result.hsps[:1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "moved-sauce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">sp|Q9BSU1|CP070_HUMAN\n",
      "SLGNEQWEFTLGMPLAQAVAILQKHCRIIKNVQVLYSEQSPLSHDLILNLTQDGIKLMFD\n",
      "AFNQRLKVIEVCDLTKVKLKYCGVHFNSQAIAPTIEQIDQSFGATHPGVYNSAEQLFHLN\n",
      "FRGLSFSFQLDSWTEAPKYEPNFAHGLASLQIPHGATVKRMYIYSGNSLQDTKAPMMPLS\n",
      "CFLGNVYAESVDVLRDGTGPAGLRLRLLAAGCGPGLLADAKMRVFERSVYFGDSCQDVLS\n",
      "MLGSPHKVFYKSEDKMKIHSPSPHKQVPSKCNDYFFNYFTLGVDILFDANTHKVKKFVLH\n",
      "TNYPGHYNFNIYHRCEFKIPLAIKKENADGQTE--TCTTYSKWDNIQELLGHPVEKPVVL\n",
      "HRSSSPNNTNPFGSTFCFGLQRMIFEVMQNNHIASVTLY\n",
      ">UPF0183\n",
      "EQWE----FALGMPLAQAISILQKHCRIIKNVQVLYSEQMPLSHDLILNLTQDGIKLLFD\n",
      "ACNQRLKVIEVYDLTKVKLKYCGVHFNSQAIAPTIEQIDQSFGATHPGVYNAAEQLFHLN\n",
      "FRGLSFSFQLDSWSEAPKYEPNFAHGLASLQIPHGATVKRMYIYSGNNLQETKAPAMPLA\n",
      "CFLGNVYAECVEVLRDGAGPLGLKLRLLTAGCGPGVLADTKVRAVERSIYFGDSCQDVLS\n",
      "ALGSPHKVFYKSEDKMKIHSPSPHKQVPSKCNDYFFNYYILGVDILFDSTTHLVKKFVLH\n",
      "TNFPGHYNFNIYHRCDFKIPLIIKKDGADAHSEDCILTTYSKWDQIQELLGHPMEKPVVL\n",
      "HRSSSANNTNPFGSTFCFGLQRMIFEVMQNNHIASVTLY\n"
     ]
    }
   ],
   "source": [
    "for result in results[:1]:\n",
    "    for hsp in result.hsps[:1]:\n",
    "        '''\n",
    "        print(hsp.score)\n",
    "        print(\"***------HELPFUL DATA SEPARATOR-------***\")\n",
    "        print(hsp.query.id)\n",
    "        print(hsp.hit.description) # I guessed `.hit.description` this based on `self.assertEqual(\"T\", str(hsp.hit.seq))` in test_SearchIO_hhsuite2_text.py because I didn't see any example for this one)\n",
    "        print(\"***------HELPFUL DATA SEPARATOR-------***\")\n",
    "        print(hsp.hit.seq)\n",
    "        print(\"***------HELPFUL DATA SEPARATOR-------***\")\n",
    "        print(hsp.query.seq)\n",
    "        print(\"***------HELPFUL DATA SEPARATOR-------***\")\n",
    "        print(generate_seq_chunks(hsp.query.seq))\n",
    "        print(generate_seq_chunks(hsp.hit.seq))\n",
    "        '''\n",
    "        seq_fa_query = \">\" + hsp.query.id.split()[0] + \"\\n\"+\"\\n\".join(\n",
    "                    generate_seq_chunks(str(hsp.query.seq)))\n",
    "        print(seq_fa_query)\n",
    "        seq_fa_hit = \">\" + hsp.hit.description.split()[0] + \"\\n\"+\"\\n\".join(\n",
    "                    generate_seq_chunks(str(hsp.hit.seq)))\n",
    "        print(seq_fa_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-marking",
   "metadata": {},
   "source": [
    "So that took the aligned sequences in the HH-suite3 results `.hhr` file, extracted them as sequences, and made multi-sequence aligned FASTA format sequences for the hit and query of the best hit.\n",
    "\n",
    "**Note the aligned sequences have the same length even though if you discount the gaps, they are not the same length.**  \n",
    "In other words, the interleaved complex alignment blocks have been converted to aligned FASTA format sequence entries.\n",
    "\n",
    "\n",
    "You may wish to review the sequences in the alignment of the query to the first hit in `hhsearch_q9bsu1_uniclust_w_ss_pfamA_30.hhr` to understand what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-protection",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Continue on with the next notebook in the series, [???](???.ipynb). That notebook builds on the ground work here and in previous notebooks in this series to demonstrate ???.\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
