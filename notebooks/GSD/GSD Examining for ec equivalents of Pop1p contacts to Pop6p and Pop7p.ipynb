{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSD Examining for ec equivalents of Pop1p contacts to Pop6p and Pop7p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This effort is based on my notebook [Using snakemake with multiple chains or structures to report if residues interacting with a specific chain have equivalent residues in hhsuite-generated alignments](https://nbviewer.jupyter.org/github/fomightez/hhsuite3-binder/blob/main/notebooks/Using%20snakemake%20with%20multiple%20chains%20or%20structures%20to%20report%20if%20residues%20interacting%20with%20a%20specific%20chain%20have%20equivalent%20residues%20in%20hhsuite-generated%20alignments.ipynb) in order to look at ec equivalents of residues in Pop1p that contact Pop6p and Pop6p.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step #1:** Make a table with columns separated by spaces and each line as a row that specificies structures, chains, and hhr results file(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "6agb B F results_S288C_POP1.hhr 1 True True\n",
    "6agb B G results_S288C_POP1.hhr 1 True True\n",
    "6ah3 B F results_S288C_POP1.hhr 1 True True\n",
    "6ah3 B G results_S288C_POP1.hhr 1 True True\n",
    "7c79 B F results_S288C_POP1.hhr 1 True True\n",
    "7c79 B G results_S288C_POP1.hhr 1 True True\n",
    "7c7a B F results_S288C_POP1.hhr 1 True True\n",
    "7c7a B G results_S288C_POP1.hhr 1 True True\n",
    "6w6v B F results_S288C_POP1.hhr 1 True True\n",
    "6w6v B G results_S288C_POP1.hhr 1 True True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step #2:** Save the table with the following name, `equiv_check_matrix.txt`. It has to have that name for the table to be recognized and processed to make the Jupyter notbeook files with the reports.\n",
    "\n",
    "Running following will generate an `equiv_check_matrix.txt` file here with the indicated content; however, you can, and will want to, skip running this if already made your own table. If you run it, it will replace your file though. Alternatively, you can edit the code below to make a table with the contents that interest you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 's' (str) to file 'equiv_check_matrix.txt'.\n"
     ]
    }
   ],
   "source": [
    "s='''6agb B F results_S288C_POP1.hhr 1 True True\n",
    "6agb B G results_S288C_POP1.hhr 1 True True\n",
    "6ah3 B F results_S288C_POP1.hhr 1 True True\n",
    "6ah3 B G results_S288C_POP1.hhr 1 True True\n",
    "7c79 B F results_S288C_POP1.hhr 1 True True\n",
    "7c79 B G results_S288C_POP1.hhr 1 True True\n",
    "7c7a B F results_S288C_POP1.hhr 1 True True\n",
    "7c7a B G results_S288C_POP1.hhr 1 True True\n",
    "6w6v B F results_S288C_POP1.hhr 1 True True\n",
    "6w6v B G results_S288C_POP1.hhr 1 True True\n",
    "'''\n",
    "%store s >equiv_check_matrix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #3:** Get the HH-suite3-generated results files (`*.hhr` files).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT THE *.hhr FILE, `results_S288C_POP1.hhr`,IN THE DIRECTORY WITH THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #4:** Copy the Snakemake Snakefile to this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 21926  100 21926    0     0  31294      0 --:--:-- --:--:-- --:--:-- 31278\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"equiv_snakefile\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -OL https://raw.githubusercontent.com/fomightez/hhsuite3-binder/main/notebooks/equiv_snakefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #5:** Run snakemake and point it at the corresponding snake file `equiv_snakefile` and it will process the `equiv_check_matrix.txt` file to extract the information and make individual notebooks corresponding to analysis of the interactions for each line. This will be very similar to running the previous notebooks in this series with the items spelled out on each line.  \n",
    "The file snakemake uses in this pipeline, named `equiv_snakefile`, is already here. It is related to Python scripts and you can examine the text if you wis.  \n",
    "It will take about a minute or less to complete if you are running the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job                                             count    min threads    max threads\n",
      "--------------------------------------------  -------  -------------  -------------\n",
      "all                                                 1              1              1\n",
      "convert_scripts_to_nb_and_run_using_jupytext       10              1              1\n",
      "make_archive                                        1              1              1\n",
      "read_table_and_create_py                            1              1              1\n",
      "total                                              13              1              1\n",
      "\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:07:55 2021]\u001b[0m\n",
      "\u001b[32mrule read_table_and_create_py:\n",
      "    input: equiv_check_matrix.txt\n",
      "    output: equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.py, equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.py, equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.py, equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.py, equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.py, equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.py, equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.py, equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.py, equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.py, equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.py\n",
      "    jobid: 3\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:07:56 2021]\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m1 of 13 steps (8%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:07:56 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 5\n",
      "    wildcards: details=6ah3_B_F_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:03 2021]\u001b[0m\n",
      "\u001b[32mFinished job 5.\u001b[0m\n",
      "\u001b[32m2 of 13 steps (15%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:03 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 6\n",
      "    wildcards: details=6ah3_B_G_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:08 2021]\u001b[0m\n",
      "\u001b[32mFinished job 6.\u001b[0m\n",
      "\u001b[32m3 of 13 steps (23%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:08 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 8\n",
      "    wildcards: details=7c79_B_G_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:11 2021]\u001b[0m\n",
      "\u001b[32mFinished job 8.\u001b[0m\n",
      "\u001b[32m4 of 13 steps (31%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:11 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 10\n",
      "    wildcards: details=7c7a_B_G_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:15 2021]\u001b[0m\n",
      "\u001b[32mFinished job 10.\u001b[0m\n",
      "\u001b[32m5 of 13 steps (38%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:15 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 12\n",
      "    wildcards: details=6w6v_B_G_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:20 2021]\u001b[0m\n",
      "\u001b[32mFinished job 12.\u001b[0m\n",
      "\u001b[32m6 of 13 steps (46%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:20 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 2\n",
      "    wildcards: details=6agb_B_F_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:24 2021]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m7 of 13 steps (54%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:24 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 9\n",
      "    wildcards: details=7c7a_B_F_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:28 2021]\u001b[0m\n",
      "\u001b[32mFinished job 9.\u001b[0m\n",
      "\u001b[32m8 of 13 steps (62%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:28 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 4\n",
      "    wildcards: details=6agb_B_G_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:32 2021]\u001b[0m\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "\u001b[32m9 of 13 steps (69%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:32 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 11\n",
      "    wildcards: details=6w6v_B_F_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:36 2021]\u001b[0m\n",
      "\u001b[32mFinished job 11.\u001b[0m\n",
      "\u001b[32m10 of 13 steps (77%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:36 2021]\u001b[0m\n",
      "\u001b[32mrule convert_scripts_to_nb_and_run_using_jupytext:\n",
      "    input: equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.py\n",
      "    output: equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.ipynb\n",
      "    jobid: 7\n",
      "    wildcards: details=7c79_B_F_results_S288C_POP1.hhr\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "[jupytext] Reading equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.py in format py\n",
      "[jupytext] Executing notebook with kernel python3\n",
      "[jupytext] Writing equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.ipynb\n",
      "\u001b[32m[Mon Jul 19 21:08:40 2021]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m11 of 13 steps (85%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:40 2021]\u001b[0m\n",
      "\u001b[32mrule make_archive:\n",
      "    input: equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.ipynb, equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.ipynb, equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.ipynb, equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.ipynb, equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.ipynb, equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.ipynb, equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.ipynb, equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.ipynb, equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.ipynb, equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.ipynb\n",
      "    output: equivalents_report_nbsJul1920212107.tar.gz\n",
      "    jobid: 1\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "Be sure to download equivalents_report_nbsJul1920212107.tar.gz.\n",
      "\u001b[32m[Mon Jul 19 21:08:40 2021]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m12 of 13 steps (92%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:40 2021]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: equivalents_report_nbsJul1920212107.tar.gz\n",
      "    jobid: 0\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Mon Jul 19 21:08:40 2021]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m13 of 13 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /home/jovyan/notebooks/GSD/.snakemake/log/2021-07-19T210754.408436.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -s equiv_snakefile --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For those knowlegeable with snakemake, I will note that I set the number of cores as one because I was finding with eight that occasionally a race condition would ensue where some of the auxillary scripts fetched in the course of running the report-generating notebooks would overwrite each other as they was being accessed by another notebook causing failures. Using one core avoids that hazard. I will add though that in most cases if you use multiple cores, you can easily get the additional files and a new archive made by running snakemake with your chosen number of cores again.  I never saw a race hazard with my clean rule, and so if you want to quickly start over you can run `!snakemake -s equiv_snakefile --cores 8 clean`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the reports clearer by substituting in the names of the proteins in place of the Chain designations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2name_pairs = {\n",
    "    \"Chain B\":\"Pop1p\",\n",
    "    \"Chain F\":\"Pop6p\",\n",
    "    \"Chain G\":\"Pop7p\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain designations swapped for names in equivalents_report_for_6agb_B_G_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_6agb_B_F_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_7c7a_B_F_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_6w6v_B_G_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_6ah3_B_F_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_6w6v_B_F_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_7c7a_B_G_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_6ah3_B_G_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_7c79_B_G_results_S288C_POP1.hhr.ipynb.\n",
      "Chain designations swapped for names in equivalents_report_for_7c79_B_F_results_S288C_POP1.hhr.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# Make a list of the report-containing notebooks.\n",
    "prefix_for_report_nbs = \"equivalents_report_for_\"\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import re\n",
    "equivalents_report_nb_pattern = f\"{prefix_for_report_nbs}*.ipynb\"\n",
    "equivalents_report_nbs = []\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, equivalents_report_nb_pattern):\n",
    "        equivalents_report_nbs.append(file)\n",
    "def make_swaps(file_name,key_value_pairs):\n",
    "    '''\n",
    "    Takes a file name and edits every occurence of each key in all of them,\n",
    "    replacing that text with the corresponding value.\n",
    "    Saves the fixed file. Nothing is returned from this function.\n",
    "    '''\n",
    "    output_file_name = \"temp.txt\"\n",
    "    with open(file_name, 'r') as thefile:\n",
    "        nb_text=thefile.read()\n",
    "    for k,v in key_value_pairs.items():\n",
    "        #nb_text=nb_text.replace(k.lower(),v) # if wasn't case insensitive for key\n",
    "        # case-insensitive string replacement from https://stackoverflow.com/a/919067/8508004\n",
    "        insensitive = re.compile(re.escape(k), re.IGNORECASE)\n",
    "        nb_text = insensitive.sub(v, nb_text)\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "        output_file.write(nb_text)\n",
    "    # replace the original file with edited\n",
    "    !mv {output_file_name} {file_name}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"Chain designations swapped for names in {}.\\n\".format(file_name))\n",
    "\n",
    "for nbn in equivalents_report_nbs:\n",
    "    make_swaps(nbn,chain2name_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a new archive with the substituted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be sure to download equivalents_report_nbsJul1920212108.tar.gz."
     ]
    }
   ],
   "source": [
    "# delete the archive withOUT the susbstitured protein names\n",
    "!rm equivalents_report_nbs*.tar.gz\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "results_archive = f\"equivalents_report_nbs{now.strftime('%b%d%Y%H%M')}.tar.gz\"\n",
    "!tar -czf {results_archive}  {\" \".join(equivalents_report_nbs)}\n",
    "sys.stderr.write(f\"Be sure to download {results_archive}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #4:** Verify the Jupyter notebooks with the reports were generated.  \n",
    "You can go to the dashboard and see the ouput of running snakemake. To do that click on the Jupyter logo in the upper left top of this notebook and on that page you'll look in  the notebooks directory and you should see files that begin with `equivalents_report_` and end with `.ipynb`. You can examine some of them to insure all is as expected.\n",
    "\n",
    "If things seem to be working and you haven't run your data yet, run `!snakemake -s equiv_snakefile --cores 8 clean` in a cell to reset things, and then edit & save `equiv_check_matrix.txt` to have your information, and then run the `!snakemake -s equiv_snakefile --cores 1` step above, again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #5:** If this was anyting other than the demonstration run, download the archive containing all the Jupyter notebooks bundled together.  \n",
    "For ease in downloading, all the created notebooks have been saved as a compressed archive so that you only need to retieve and keep track of one file. The file you are looking for begins with `equivalents_report_nbs` in front of a date/time stamp and ends with `.tar.gz`. The snakemake run will actually highlight this archive towards the very bottom of the run, following the words 'Be sure to download'.  \n",
    "**Download that file from this remote, temporary session to your local computer.** You should see this archive file ending in `.tar.gz` on the dashboard. Toggle next to it to select it and then select `Download` to bring it from the remote Jupyterhub session to your computer. If you don't retrieve that file and the session ends, you'll need to re-run to get the results again.\n",
    "\n",
    "You should be able to unpack that archive using your favorite software to extract compressed files. If that is proving difficult, you can always reopen a session like you did to run this series of notebooks and upload the archive and then run the following command in a Jupyter notebook cellk to unpack it:\n",
    "\n",
    "```bash\n",
    "!tar xzf equivalents_report_nbs*\n",
    "```\n",
    "\n",
    "(If you are running that command on the command line, leave off the exclamation book.)\n",
    "You can then examine the files in the session or download the individual Jupyter notebooks similar to the advice on how to download the archive given above.\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "Enjoy.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
