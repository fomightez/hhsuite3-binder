{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frequent-support",
   "metadata": {},
   "source": [
    "# GSD Summarizing ec equivalency data of Pop1p residues that interact with Pop6p and Pop7p in S. cerevisiae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-jersey",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "**Step#1. Provide the input.**\n",
    "\n",
    "Put the file, `equivalents_report_nbsJul1920212108.tar.gz`, in the directory with this notebook.  \n",
    "\n",
    "**Step#2. Unpack the archive.**\n",
    "\n",
    "Run the next cell to extract that archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf equivalents_report_nbsJul1920212108.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-gospel",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-foundation",
   "metadata": {},
   "source": [
    "First collect the data from the `equivalents_report_` data notebooks to make a table with the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the report-containing notebooks. (recycled from `GSD Examining for ... equivalents of ....ipynb` notebook)\n",
    "import glob\n",
    "prefix_for_report_nbs = \"equivalents_report_for_\"\n",
    "equivalents_report_nbs = glob.glob(f\"{prefix_for_report_nbs}*.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalents_report_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data table of the info using the file names and the reports\n",
    "import re\n",
    "import pandas as pd\n",
    "protein_letter2name_dict = {\n",
    "    \"B\":\"Pop1p\",\n",
    "    \"F\":\"Pop6p\",\n",
    "    \"G\":\"Pop7p\",}\n",
    "pattern_for_in_para = re.compile(r\"\\((\\d+)\\)\")   #pattern for number between parantheses, based on https://stackoverflow.com/a/36633040/8508004\n",
    "summary_data_dict = {}\n",
    "for nb in equivalents_report_nbs:\n",
    "    pdb_id = nb.split('equivalents_report_for_')[1][:4]\n",
    "    protein1 = protein_letter2name_dict[nb.split('_')[4]]\n",
    "    protein2 = protein_letter2name_dict[nb.split('_')[5]]\n",
    "    int_desc = f'{pdb_id}_{protein1}_interactors_with_{protein2}'\n",
    "    with open(nb, 'r') as thefile:\n",
    "        content=thefile.read().replace('\\n', '')\n",
    "    num_interacting = int(content.split('RESULTS************************************',)[1].split('A total of',1)[1].split()[0].strip())\n",
    "    most_content = content.split(\"Parsing data from PDBsum to identify\",1)[1].split(\"have equivalents in the other aligned sequence\",1)[1]\n",
    "    perc_equivalent_parts = most_content.split(\",\")[1]\n",
    "    perc_equivalent = perc_equivalent_parts.split('\"')[1].split(\"%\")[0]+\"%\"\n",
    "    equivalent_num = pattern_for_in_para.findall(perc_equivalent_parts.split('\"')[1].split(\"%\")[1])[0]\n",
    "    perc_equivalent_str = perc_equivalent_parts.split('\"')[1].split(\")\")[0].strip() + \")\"\n",
    "    perc_weak_str = most_content.split(\"weakly conserved:\",1)[1].split(\")\")[0].strip() + \")\"\n",
    "    perc_weak = float(perc_weak_str.split('%')[0])\n",
    "    weak_as_num = int(pattern_for_in_para.findall(perc_weak_str)[0])\n",
    "    not_conserved_str = most_content.split(\"not conserved:\",1)[1].split(\")\")[0].strip() + \")\"\n",
    "    perc_not_cons = float(not_conserved_str.split('%')[0])\n",
    "    not_cons_as_num = int(pattern_for_in_para.findall(not_conserved_str)[0])\n",
    "    total_weak_n_not = weak_as_num + not_cons_as_num\n",
    "    perc_total_weak_n_not = perc_weak + perc_not_cons\n",
    "    perc_total_weak_n_not_str = f\"{perc_total_weak_n_not}% ({total_weak_n_not})\"\n",
    "    summary_data_dict[int_desc] = [pdb_id,protein1,protein2,num_interacting,perc_equivalent_str,perc_total_weak_n_not_str]\n",
    "df = pd.DataFrame(summary_data_dict).transpose()\n",
    "df.columns = ['PDB','Protein (& ortholog) with residues considered','Protein interacting','Number of residues from protein considered contacting the protein interacting','Percent interacting residues with equivalents in ortholog (actual #)','Percent residues with equivalents classified weakly or not conserved  (total #)']\n",
    "df = df.sort_values([df.columns[2],df.columns[0]],ascending=[True,True])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-advance",
   "metadata": {},
   "source": [
    "### INTERPRETATION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
